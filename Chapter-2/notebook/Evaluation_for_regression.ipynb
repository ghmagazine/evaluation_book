{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "610eb7e4",
   "metadata": {},
   "source": [
    "# 2章 回帰の評価指標"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458c8a8b",
   "metadata": {},
   "source": [
    "### 2-2-2 前処理とシミュレーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4650b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# AirREGEの訪問者数の情報が含まれているair_visit_data.csvというファイルをpandasのDataFrameの形式で読み込みます。\n",
    "air_visit = pd.read_csv('../data/air_visit_data.csv')\n",
    "\n",
    "# 店舗ごとに総来店者数を算出します。\n",
    "visiter_counts_by_store = air_visit.groupby(\"air_store_id\")[\"visitors\"].sum().reset_index()\n",
    "\n",
    "# 店舗ごとの総来店者数で降順にソートして総来店者数が多い上位5店舗だけ表示します。\n",
    "visiter_counts_by_store.sort_values(\"visitors\",ascending=False).reset_index(drop=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efa9ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 店舗 air_399904bdb7685ca0 の日毎の訪問者数を6日分だけ表示します。\n",
    "air_visit.query('air_store_id == \"air_399904bdb7685ca0\"').reset_index(drop=True).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521b9206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# air_visit_maxの変数に店舗 air_399904bdb7685ca0 の日毎の訪問者数のデータを全量格納します。\n",
    "air_visit_max = air_visit.query('air_store_id == \"air_399904bdb7685ca0\"').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b40e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以降では何日分のデータが含まれるかを計算します。\n",
    "# 店舗 air_399904bdb7685ca0 のデータのうち最新の日付を取得します。\n",
    "latest_date = datetime.strptime(air_visit_max.visit_date.max(), '%Y-%m-%d')\n",
    "# 店舗 air_399904bdb7685ca0 のデータのうち最も昔の日付を取得します。\n",
    "oldest_date = datetime.strptime(air_visit_max.visit_date.min(), '%Y-%m-%d')\n",
    "# 店舗 air_399904bdb7685ca0 のデータに何日分含まれているか(最も昔の日付から最新の日付までの日数)を計算して表示します。\n",
    "print(latest_date - oldest_date)\n",
    "# 店舗 air_399904bdb7685ca0 に含まれているデータの期間を表示する\n",
    "print(f\"{datetime.strftime(oldest_date, '%Y年%m月%d日')}〜{datetime.strftime(latest_date, '%Y年%m月%d日')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8a0d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 店舗情報が含まれている air_store_info.csvというファイルをpandasのDataFrameの形式で読み込みます。\n",
    "air_store = pd.read_csv(\"../data/air_store_info.csv\")\n",
    "# 店舗 air_399904bdb7685ca0 のお店の情報を表示します。\n",
    "air_store.query('air_store_id == \"air_399904bdb7685ca0\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3943e00f",
   "metadata": {},
   "source": [
    "### 2-3 平均絶対誤差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2f0513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dateutil.parser import parse\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "# AirREGEの顧客の予約情報が含まれているair_reserve.csvというファイルをpandasのDataFrameの形式で読み込みます。\n",
    "air_reserve = pd.read_csv(\"../data/air_reserve.csv\")\n",
    "air_visit_max = air_visit.query('air_store_id == \"air_399904bdb7685ca0\"').copy()\n",
    "air_reserve_max = air_reserve.query('air_store_id == \"air_399904bdb7685ca0\"').copy()\n",
    "air_store_max = air_store.query('air_store_id == \"air_399904bdb7685ca0\"').copy()\n",
    "air_visit_max.to_csv('../data/air_visit_max.csv', index=False)\n",
    "air_reserve_max.to_csv('../data/air_reserve_max.csv', index=False)\n",
    "air_store_max.to_csv('../data/air_store_info_max.csv', index=False)\n",
    "\n",
    "# 日本の休日やカレンダーの情報が含まれているdate_info.csvというファイルをpandasのDataFrameの形式で読み込みます。\n",
    "# この時カレンダーの日付(calendar_dateカラム)をvisit_dateカラムというカラム名に変更して、曜日の情報はday_of_weekカラムのものは今回は使わないので削除します。\n",
    "air_reserve = pd.read_csv(\"../data/air_reserve_max.csv\")\n",
    "air_visit = pd.read_csv(\"../data/air_visit_max.csv\")\n",
    "date_info = (\n",
    "    pd.read_csv(\"../data/date_info.csv\")\n",
    "    .rename(columns={\"calendar_date\": \"visit_date\"})\n",
    "    .drop(\"day_of_week\", axis=1)\n",
    ")\n",
    "\n",
    "# この辺りは特徴量を作成する前準備として、カラムを増やす処理を行っています\n",
    "# 予約の日時から予約日を抽出します\n",
    "air_reserve[\"visit_date\"] = air_reserve[\"visit_datetime\"].str[:10]\n",
    "# 予約した日時から予約日を抽出します\n",
    "air_reserve[\"reserve_date\"] = air_reserve[\"reserve_datetime\"].str[:10]\n",
    "# 予約日から曜日の情報を取得します\n",
    "air_reserve[\"dow\"] = pd.to_datetime(air_reserve[\"visit_date\"]).dt.dayofweek\n",
    "# 訪問者数のデータの店舗のIDと日付の情報からIDを作成します\n",
    "air_visit_max[\"id\"] = air_visit_max[\"air_store_id\"] + \"_\" + air_visit_max[\"visit_date\"]\n",
    "# 訪問者数のデータの日付の情報から曜日を抽出します\n",
    "air_visit_max[\"dow\"] = pd.to_datetime(air_visit_max[\"visit_date\"]).dt.dayofweek\n",
    "# カレンダーの日付から曜日を抽出します\n",
    "date_info[\"holiday_flg2\"] = pd.to_datetime(date_info[\"visit_date\"]).dt.dayofweek\n",
    "# .dt.dayofweekの処理により、月曜日は0、火曜日は1、水曜日は2、木曜日は3、金曜日は4、土曜日は5、日曜日は6という形で変換されています\n",
    "# そのため、以下ではカレンダーの日付が土曜日、日曜日の時もしくは店舗の休日の時はholiday_flg2カラムが1になるようにしています。\n",
    "# それ以外の場合は0になるようになっています。\n",
    "date_info[\"holiday_flg2\"] = (\n",
    "    (date_info[\"holiday_flg2\"] > 4) | (date_info[\"holiday_flg\"] == 1)\n",
    ").astype(int)\n",
    "# 訪問者数のデータ(air_visit_max)と日付の情報を含んでいるデータ(date_info)を一緒に取り扱えるようにするため、Left Outer Joinの形でDataFrameを結合します。\n",
    "air_visit_max = air_visit_max.merge(\n",
    "    date_info[[\"visit_date\", \"holiday_flg\", \"holiday_flg2\"]],\n",
    "    on=[\"visit_date\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "\n",
    "# left Outer Joinした後に残る重複しているカラムを消すためのヘルパー関数\n",
    "def left_merge(data1, data2, on):\n",
    "    # data1とdata2_tempをonのキーを用いて、Left Outer Joinする\n",
    "    result = data1.merge(data2, on=on, how=\"left\")\n",
    "    # data2のカラム名のうち、onに存在していないカラム名の一覧を取得する\n",
    "    data2_columns = [f for f in data2.columns if f not in on]\n",
    "    # data2のカラムに存在しているon以外のカラム名の値だけを取り出す\n",
    "    result = result[data2_columns]\n",
    "    return result\n",
    "\n",
    "\n",
    "# day1からday2までの日数を求める関数\n",
    "def diff_of_days(day1, day2):\n",
    "    days = (parse(day1[:10]) - parse(day2[:10])).days\n",
    "    return days\n",
    "\n",
    "\n",
    "# 日付を加算する関数\n",
    "def date_add_days(start_date, days):\n",
    "    end_date = parse(start_date[:10]) + timedelta(days=days)\n",
    "    end_date = end_date.strftime(\"%Y-%m-%d\")\n",
    "    return end_date\n",
    "\n",
    "\n",
    "def calculate_label(end_date, n_day, df_visit, df_date):\n",
    "    # データの期間を絞り込む範囲を指定するためにlabelの終了日を算出\n",
    "    label_end_date = date_add_days(end_date, n_day)\n",
    "    # データの期間を絞り込む。visit_dateがlabel_end_dateより前で、visit_dateがend_dateより後である期間のデータだけを取得する\n",
    "    label = df_visit[\n",
    "        (df_visit[\"visit_date\"] < label_end_date) & (df_visit[\"visit_date\"] >= end_date)\n",
    "    ].copy()\n",
    "    # end_dateをカラムとして追加する\n",
    "    label[\"end_date\"] = end_date\n",
    "    # visit_dateからend_dateまでの日数を求める\n",
    "    label[\"diff_of_day\"] = label[\"visit_date\"].apply(\n",
    "        lambda x: diff_of_days(x, end_date)\n",
    "    )\n",
    "    # visit_dateの月の情報を抽出する(例: 2022/01/02 -> 1)\n",
    "    label[\"month\"] = label[\"visit_date\"].str[5:7].astype(int)\n",
    "    # visit_dateの年の情報を抽出する(例: 2022/01/01 -> 2022)\n",
    "    label[\"year\"] = label[\"visit_date\"].str[:4].astype(int)\n",
    "    # 3日後・2日後・1日後・1日前が休日かどうかを算出する\n",
    "    for i in [3, 2, 1, -1]:\n",
    "        date_info_temp = df_date.copy()\n",
    "        # visit_dateカラムの値にi日加算した日付でvisit_dateカラムを上書きする\n",
    "        date_info_temp[\"visit_date\"] = date_info_temp[\"visit_date\"].apply(\n",
    "            lambda x: date_add_days(x, i)\n",
    "        )\n",
    "        # date_info_tempのholiday_flgカラムとholiday_flg2カラムをiの値を接尾語として使ってカラム名を変える\n",
    "        # 次の行でのマージ時に同じカラム名のものをマージするとカラム名が機械的にholiday_flgならholiday_flg_xとholiday_flg_yに変更されてしまうためこうしている\n",
    "        date_info_temp.rename(\n",
    "            columns={\n",
    "                \"holiday_flg\": \"ahead_holiday_{}\".format(i),\n",
    "                \"holiday_flg2\": \"ahead_holiday2_{}\".format(i),\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "        # visit_dateカラムをキーにして、labelとdate_info_tempでLeft Outer Joinでマージする\n",
    "        label = label.merge(date_info_temp, on=[\"visit_date\"], how=\"left\")\n",
    "    label = label.reset_index(drop=True)\n",
    "    return label\n",
    "\n",
    "\n",
    "def calculate_store_visitor_feature(label, end_date, n_day, df_visit):\n",
    "    # データの期間を絞り込む範囲を指定するために開始日を算出\n",
    "    start_date = date_add_days(end_date, -n_day)\n",
    "    # データの期間を絞り込む。visit_dateが開始日より後から終了日より前である期間のデータだけを取得する\n",
    "    data_temp = df_visit[\n",
    "        (df_visit.visit_date < end_date) & (df_visit.visit_date > start_date)\n",
    "    ].copy()\n",
    "    # 店舗IDごとに訪問者数を最小値、平均、中央値、最大値、カウント、標準偏差、歪度の各統計量で集計する\n",
    "    result = data_temp.groupby([\"air_store_id\"], as_index=False)[\"visitors\"].agg(\n",
    "        {\n",
    "            \"store_min{}\".format(n_day): \"min\",\n",
    "            \"store_mean{}\".format(n_day): \"mean\",\n",
    "            \"store_median{}\".format(n_day): \"median\",\n",
    "            \"store_max{}\".format(n_day): \"max\",\n",
    "            \"store_count{}\".format(n_day): \"count\",\n",
    "            \"store_std{}\".format(n_day): \"std\",\n",
    "            \"store_skew{}\".format(n_day): \"skew\",\n",
    "        }\n",
    "    )\n",
    "    # labelにconcatで連結できるようにするために、labelとここで作成した特徴量を結合して、特徴量のカラムだけを取り出す。\n",
    "    result = left_merge(label, result, on=[\"air_store_id\"]).fillna(0)\n",
    "    return result\n",
    "\n",
    "\n",
    "def calculate_store_week_feature(label, end_date, n_day, df_visit):\n",
    "    # 開始日を算出\n",
    "    start_date = date_add_days(end_date, -n_day)\n",
    "    # データの期間を絞り込む。visit_dateが開始日より後から終了日より前である期間のデータだけを取得する\n",
    "    data_temp = df_visit[\n",
    "        (df_visit.visit_date < end_date) & (df_visit.visit_date > start_date)\n",
    "    ].copy()\n",
    "    # 曜日ごとの訪問者数を最小値、平均、中央値、最大値、カウント、標準偏差、歪度の各統計量で集計する\n",
    "    result = data_temp.groupby([\"air_store_id\", \"dow\"], as_index=False)[\"visitors\"].agg(\n",
    "        {\n",
    "            \"store_dow_min{}\".format(n_day): \"min\",\n",
    "            \"store_dow_mean{}\".format(n_day): \"mean\",\n",
    "            \"store_dow_median{}\".format(n_day): \"median\",\n",
    "            \"store_dow_max{}\".format(n_day): \"max\",\n",
    "            \"store_dow_count{}\".format(n_day): \"count\",\n",
    "            \"store_dow_std{}\".format(n_day): \"std\",\n",
    "            \"store_dow_skew{}\".format(n_day): \"skew\",\n",
    "        }\n",
    "    )\n",
    "    # labelにconcatで連結できるようにするために、labelとここで作成した特徴量を結合して、特徴量のカラムだけを取り出す。\n",
    "    result = left_merge(label, result, on=[\"air_store_id\", \"dow\"]).fillna(0)\n",
    "    return result\n",
    "\n",
    "\n",
    "def calculate_store_week_diff_feature(label, end_date, n_day, df_visit):\n",
    "    # 開始日を算出\n",
    "    start_date = date_add_days(end_date, -n_day)\n",
    "    # データの期間を絞り込む。visit_dateが開始日より後から終了日より前である期間のデータだけを取得する\n",
    "    data_temp = df_visit[\n",
    "        (df_visit.visit_date < end_date) & (df_visit.visit_date > start_date)\n",
    "    ].copy()\n",
    "    # 日ごとの訪問者数を行方向から列方向のデータに変更する\n",
    "    result = data_temp.set_index([\"air_store_id\", \"visit_date\"])[\"visitors\"].unstack()\n",
    "    # 訪問者数の1日前との差分を求める\n",
    "    result = result.diff(axis=1).iloc[:, 1:]\n",
    "    # カラム名を取得\n",
    "    column_names = result.columns\n",
    "    # 差分の平均、標準偏差、最大、最小の統計量を出して特徴量にする\n",
    "    result[\"store_diff_mean\"] = np.abs(result[column_names]).mean(axis=1)\n",
    "    result[\"store_diff_std\"] = result[column_names].std(axis=1)\n",
    "    result[\"store_diff_max\"] = result[column_names].max(axis=1)\n",
    "    result[\"store_diff_min\"] = result[column_names].min(axis=1)\n",
    "    # labelにconcatで連結できるようにするために、labelとここで作成した特徴量を結合して、特徴量のカラムだけを取り出す。\n",
    "    result = left_merge(\n",
    "        label,\n",
    "        result[\n",
    "            [\"store_diff_mean\", \"store_diff_std\", \"store_diff_max\", \"store_diff_min\"]\n",
    "        ],\n",
    "        on=[\"air_store_id\"],\n",
    "    ).fillna(0)\n",
    "    return result\n",
    "\n",
    "\n",
    "def calculate_store_all_week_feature(label, end_date, n_day, df_visit):\n",
    "    # 開始日を算出\n",
    "    start_date = date_add_days(end_date, -n_day)\n",
    "    # データの期間を絞り込む。visit_dateが開始日より後から終了日より前である期間のデータだけを取得する\n",
    "    data_temp = df_visit[\n",
    "        (df_visit.visit_date < end_date) & (df_visit.visit_date > start_date)\n",
    "    ].copy()\n",
    "    # 店舗・曜日ごとの訪問者数を平均、中央値、最大値、カウントの4つの統計量を出す\n",
    "    result_temp = data_temp.groupby([\"air_store_id\", \"dow\"], as_index=False)[\n",
    "        \"visitors\"\n",
    "    ].agg(\n",
    "        {\n",
    "            \"store_dow_mean{}\".format(n_day): \"mean\",\n",
    "            \"store_dow_median{}\".format(n_day): \"median\",\n",
    "            \"store_dow_sum{}\".format(n_day): \"max\",\n",
    "            \"store_dow_count{}\".format(n_day): \"count\",\n",
    "        }\n",
    "    )\n",
    "    result = pd.DataFrame()\n",
    "    # 全ての曜日に対して、特徴量を生成する\n",
    "    for i in range(7):\n",
    "        # 曜日の番号で絞り込みをかける。カラム名の前に曜日の番号を付与する\n",
    "        result_sub = (\n",
    "            result_temp[result_temp[\"dow\"] == i]\n",
    "            .copy()\n",
    "            .set_index(\"air_store_id\")\n",
    "            .add_prefix(str(i))\n",
    "        )\n",
    "        # labelにconcatで連結できるようにするために、labelとここで作成した特徴量を結合して、特徴量のカラムだけを取り出す。\n",
    "        result_sub = left_merge(label, result_sub, on=[\"air_store_id\"]).fillna(0)\n",
    "        # 作成した曜日の特徴量を列に追加\n",
    "        result = pd.concat([result, result_sub], axis=1)\n",
    "    return result\n",
    "\n",
    "\n",
    "def calculate_store_holiday_feature(label, end_date, n_day, df_visit):\n",
    "    # 開始日を算出\n",
    "    start_date = date_add_days(end_date, -n_day)\n",
    "    # データの期間を絞り込む。visit_dateが開始日より後から終了日より前である期間のデータだけを取得する\n",
    "    data_temp = df_visit[\n",
    "        (df_visit.visit_date < end_date) & (df_visit.visit_date > start_date)\n",
    "    ].copy()\n",
    "    # date_info.csvのholiday_flgを使って休日と平日でそれぞれ訪問者数を最小値、平均、中央値、最大値、カウント、標準偏差、歪度の各統計量を集計する\n",
    "    result1 = data_temp.groupby([\"air_store_id\", \"holiday_flg\"], as_index=False)[\n",
    "        \"visitors\"\n",
    "    ].agg(\n",
    "        {\n",
    "            \"store_holiday_min{}\".format(n_day): \"min\",\n",
    "            \"store_holiday_mean{}\".format(n_day): \"mean\",\n",
    "            \"store_holiday_median{}\".format(n_day): \"median\",\n",
    "            \"store_holiday_max{}\".format(n_day): \"max\",\n",
    "            \"store_holiday_count{}\".format(n_day): \"count\",\n",
    "            \"store_holiday_std{}\".format(n_day): \"std\",\n",
    "            \"store_holiday_skew{}\".format(n_day): \"skew\",\n",
    "        }\n",
    "    )\n",
    "    # labelにconcatで連結できるようにするために、labelとここで作成した特徴量を結合して、特徴量のカラムだけを取り出す。\n",
    "    result1 = left_merge(label, result1, on=[\"air_store_id\", \"holiday_flg\"]).fillna(0)\n",
    "\n",
    "    # カレンダーの日付が土曜日、日曜日の時もしくは店舗の休日の時とそうでない時でそれぞれ訪問者数を最小値、平均、中央値、最大値、カウント、標準偏差、歪度の各統計量を集計する\n",
    "    result2 = data_temp.groupby([\"air_store_id\", \"holiday_flg2\"], as_index=False)[\n",
    "        \"visitors\"\n",
    "    ].agg(\n",
    "        {\n",
    "            \"store_holiday2_min{}\".format(n_day): \"min\",\n",
    "            \"store_holiday2_mean{}\".format(n_day): \"mean\",\n",
    "            \"store_holiday2_median{}\".format(n_day): \"median\",\n",
    "            \"store_holiday2_max{}\".format(n_day): \"max\",\n",
    "            \"store_holiday2_count{}\".format(n_day): \"count\",\n",
    "            \"store_holiday2_std{}\".format(n_day): \"std\",\n",
    "            \"store_holiday2_skew{}\".format(n_day): \"skew\",\n",
    "        }\n",
    "    )\n",
    "    # labelにconcatで連結できるようにするために、labelとここで作成した特徴量を結合して、特徴量のカラムだけを取り出す。\n",
    "    result2 = left_merge(label, result2, on=[\"air_store_id\", \"holiday_flg2\"]).fillna(0)\n",
    "    # ここで作成した特徴量を結合する\n",
    "    result = pd.concat([result1, result2], axis=1)\n",
    "    return result\n",
    "\n",
    "\n",
    "def calculate_first_last_time_feature(label, end_date, n_day, df_visit):\n",
    "    # 開始日を算出\n",
    "    start_date = date_add_days(end_date, -n_day)\n",
    "    # データの期間を絞り込む。visit_dateが開始日より後から終了日より前である期間のデータだけを取得する\n",
    "    data_temp = df_visit[\n",
    "        (df_visit.visit_date < end_date) & (df_visit.visit_date > start_date)\n",
    "    ].copy()\n",
    "    # 訪問日付を昇順でソートする\n",
    "    data_temp = data_temp.sort_values(\"visit_date\")\n",
    "\n",
    "    # 絞り込んだ期間のデータの最大と最小の日付の終了日からの日数を集計する\n",
    "    result = (\n",
    "        data_temp.groupby(\"air_store_id\")[\"visit_date\"]\n",
    "        .agg(\n",
    "            [\n",
    "                lambda x: diff_of_days(end_date, np.min(x)),\n",
    "                lambda x: diff_of_days(end_date, np.max(x)),\n",
    "            ]\n",
    "        )\n",
    "        .rename(columns={\"<lambda_0>\": \"first_time\", \"<lambda_1>\": \"last_time\"})\n",
    "    )\n",
    "    # labelにconcatで連結できるようにするために、labelとここで作成した特徴量を結合して、特徴量のカラムだけを取り出す。\n",
    "    result = left_merge(label, result, on=[\"air_store_id\"]).fillna(0)\n",
    "    return result\n",
    "\n",
    "\n",
    "def calculate_reserve_feature(label, end_date, n_day, df_reserve):\n",
    "    # labelの終了日を算出する\n",
    "    label_end_date = date_add_days(end_date, n_day)\n",
    "    # visit_dateが終了日以降からlabelの終了日より前までの期間であり、予約日が終了日より前のデータだけに絞り込む。\n",
    "    air_reserve_temp = df_reserve[\n",
    "        (df_reserve.visit_date >= end_date)\n",
    "        & (df_reserve.visit_date < label_end_date)\n",
    "        & (df_reserve.reserve_date < end_date)\n",
    "    ].copy()\n",
    "    # Left Outer Joinで絞り込んだデータとdf_reserveを結合する\n",
    "    air_reserve_temp = air_reserve_temp.merge(df_reserve, on=\"air_store_id\", how=\"left\")\n",
    "    # 訪問日時から予約日時までの日数をカラムに加える\n",
    "    air_reserve_temp[\"diff_time\"] = (\n",
    "        pd.to_datetime(df_reserve[\"visit_datetime\"])\n",
    "        - pd.to_datetime(df_reserve[\"reserve_datetime\"])\n",
    "    ).dt.days\n",
    "    air_reserve_temp = air_reserve_temp.merge(df_reserve, on=\"air_store_id\")\n",
    "    # 店舗・訪問日ごとに予約した訪問者数の合計とカウントを集計する\n",
    "    air_result = air_reserve_temp.groupby([\"air_store_id\", \"visit_date\"])[\n",
    "        \"reserve_visitors\"\n",
    "    ].agg(\n",
    "        air_reserve_visitors=\"sum\",\n",
    "        air_reserve_count=\"count\",\n",
    "    )\n",
    "    # Nanを0で埋めて整形する\n",
    "    air_result = air_result.unstack().fillna(0).stack()\n",
    "    # 店舗・訪問日ごとに訪問日時から予約日時までの日数の平均を求める。\n",
    "    air_store_diff_time_mean = air_reserve_temp.groupby([\"air_store_id\", \"visit_date\"])[\n",
    "        \"diff_time\"\n",
    "    ].agg(air_store_diff_time_mean=\"mean\")\n",
    "\n",
    "    # 店舗の区別をせず、訪問日ごとに訪問日時から予約日時までの日数の平均を求める。\n",
    "    air_diff_time_mean = air_reserve_temp.groupby([\"visit_date\"])[\"diff_time\"].agg(\n",
    "        air_diff_time_mean=\"mean\"\n",
    "    )\n",
    "    # 店舗の区別をせず、訪問日ごとに予約者数の合計、カウントを求める。\n",
    "    air_date_result = air_reserve_temp.groupby([\"visit_date\"])[\"reserve_visitors\"].agg(\n",
    "        air_date_visitors=\"sum\", air_date_count=\"count\"\n",
    "    )\n",
    "    # labelにconcatで連結できるようにするために、labelとここで作成した特徴量を結合して、特徴量のカラムだけを取り出す。\n",
    "    air_result = left_merge(\n",
    "        label, air_result, on=[\"air_store_id\", \"visit_date\"]\n",
    "    ).fillna(0)\n",
    "    # labelにconcatで連結できるようにするために、labelとここで作成した特徴量を結合して、特徴量のカラムだけを取り出す。\n",
    "    air_store_diff_time_mean = left_merge(\n",
    "        label, air_store_diff_time_mean, on=[\"air_store_id\", \"visit_date\"]\n",
    "    ).fillna(0)\n",
    "    # labelにconcatで連結できるようにするために、labelとここで作成した特徴量を結合して、特徴量のカラムだけを取り出す。\n",
    "    air_date_result = left_merge(label, air_date_result, on=[\"visit_date\"]).fillna(0)\n",
    "    # labelにconcatで連結できるようにするために、labelとここで作成した特徴量を結合して、特徴量のカラムだけを取り出す。\n",
    "    air_diff_time_mean = left_merge(\n",
    "        label, air_diff_time_mean, on=[\"visit_date\"]\n",
    "    ).fillna(0)\n",
    "    # ここで作成した特徴量を結合する\n",
    "    result = pd.concat(\n",
    "        [air_result, air_date_result, air_store_diff_time_mean, air_diff_time_mean],\n",
    "        axis=1,\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "def make_features(end_date, n_day, df_visit, df_reserve, df_date):\n",
    "    t0 = time.time()\n",
    "    result = []\n",
    "\n",
    "    # n_day-1日間のデータから終了日、終了日からの日数、月、年、3日後・2日後・1日後・1日前が休日かどうかの特徴量に追加\n",
    "    label = calculate_label(end_date, n_day, df_visit, df_date)\n",
    "    result.append(label)\n",
    "\n",
    "    # 56-2=54日間・28-2=26日間・14-2=12日間の店舗IDごとの訪問者数を最小値、平均、中央値、最大値、カウント、標準偏差、歪度の各統計量の特徴量に追加\n",
    "    result.append(calculate_store_visitor_feature(label, end_date, 56, df_visit))\n",
    "    result.append(calculate_store_visitor_feature(label, end_date, 28, df_visit))\n",
    "    result.append(calculate_store_visitor_feature(label, end_date, 14, df_visit))\n",
    "\n",
    "    # 56-2=54日間・28-2=26日間・14-2=12日間の曜日ごとの訪問者数を最小値、平均、中央値、最大値、カウント、標準偏差、歪度の各統計量の特徴量に追加\n",
    "    result.append(calculate_store_week_feature(label, end_date, 56, df_visit))\n",
    "    result.append(calculate_store_week_feature(label, end_date, 28, df_visit))\n",
    "    result.append(calculate_store_week_feature(label, end_date, 14, df_visit))\n",
    "\n",
    "    # 58日-2日=56日(4週間)の訪問者数の1日前との差分の平均、標準偏差、最大、最小の統計量の特徴量に追加\n",
    "    result.append(calculate_store_week_diff_feature(label, end_date, 58, df_visit))\n",
    "\n",
    "    # 1000-2=998日間のデータから店舗・曜日ごとの訪問者数を平均、中央値、最大値、カウントの統計量から曜日による特徴量に追加\n",
    "    result.append(calculate_store_all_week_feature(label, end_date, 1000, df_visit))\n",
    "\n",
    "    # 1000-2=998日間のデータから休日と平日でそれぞれ訪問者数を最小値、平均、中央値、最大値、カウント、標準偏差、歪度の各統計量の特徴量に追加\n",
    "    result.append(calculate_store_holiday_feature(label, end_date, 1000, df_visit))\n",
    "\n",
    "    # 予約情報を用いて以下の特徴量を作成する。\n",
    "    # ・店舗・訪問日ごとに予約した訪問者数の合計とカウント\n",
    "    # ・店舗・訪問日ごとに訪問日時から予約日時までの日数の平均\n",
    "    # ・店舗の区別をせず、訪問日ごとに訪問日時から予約日時までの日数の平均\n",
    "    # ・店舗の区別をせず、訪問日ごとに予約者数の合計とカウント\n",
    "    result.append(calculate_reserve_feature(label, end_date, n_day, df_reserve))\n",
    "\n",
    "    # 1000-2=998日間のデータからのうち、最大の日付と最小の日付からの終了日からの日数を特徴量に追加\n",
    "    result.append(calculate_first_last_time_feature(label, end_date, 1000, df_visit))\n",
    "\n",
    "    print(\"merge...\")\n",
    "    # 全特徴量をDataFrameの形で結合してまとめる\n",
    "    result = pd.concat(result, axis=1)\n",
    "\n",
    "    print(\"data shape：{}\".format(result.shape))\n",
    "    print(\"spending {}s\".format(time.time() - t0))\n",
    "    return result\n",
    "\n",
    "\n",
    "def feature_engineering(df_visit, df_reserve, df_date, is_log_transform=False):\n",
    "    df_visit_temp = df_visit.copy()\n",
    "    if is_log_transform:\n",
    "        # 訪問者数に対数をとる\n",
    "        df_visit_temp[\"visitors\"] = np.log1p(df_visit_temp[\"visitors\"])\n",
    "    train_feat = pd.DataFrame()\n",
    "    # 開始日を2017年2月13日に設定する\n",
    "    start_date = \"2017-02-13\"\n",
    "    # 開始日から58週間前まで1週ずつ遡って特徴量を作成する\n",
    "    for i in range(58):\n",
    "        train_feat_sub = make_features(\n",
    "            date_add_days(start_date, i * (-7)), 39, df_visit_temp, df_reserve, df_date\n",
    "        )\n",
    "        train_feat = pd.concat([train_feat, train_feat_sub])\n",
    "    # 開始日の1週間後から5週間後までの特徴量を作成する\n",
    "    for i in range(1, 6):\n",
    "        train_feat_sub = make_features(\n",
    "            date_add_days(start_date, i * (7)),\n",
    "            42 - (i * 7),\n",
    "            df_visit_temp,\n",
    "            df_reserve,\n",
    "            df_date,\n",
    "        )\n",
    "        train_feat = pd.concat([train_feat, train_feat_sub])\n",
    "    # テスト用の特徴量を作成する\n",
    "    test_feat = make_features(\n",
    "        date_add_days(start_date, 42), 39, df_visit_temp, df_reserve, df_date\n",
    "    )\n",
    "\n",
    "    # 予測対象のカラム名のリストを作る\n",
    "    predictors = [\n",
    "        f\n",
    "        for f in test_feat.columns\n",
    "        if f\n",
    "        not in (\n",
    "            [\n",
    "                \"id\",\n",
    "                \"air_store_id\",\n",
    "                \"visit_date\",\n",
    "                \"end_date\",\n",
    "                \"air_area_name\",\n",
    "                \"visitors\",\n",
    "                \"month\",\n",
    "                \"air_genre_name\",\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "    return train_feat, test_feat, predictors, train_feat[\"visitors\"]\n",
    "\n",
    "\n",
    "# 予測対象の訪問数に対数をとった場合の特徴量を作成する\n",
    "train_log, test_log, predictors_log, target_log = feature_engineering(\n",
    "    air_visit_max, air_reserve, date_info, is_log_transform=True\n",
    ")\n",
    "# 予測対象の訪問数から特徴量を作成する\n",
    "train, test, predictors, target = feature_engineering(\n",
    "    air_visit_max, air_reserve, date_info, is_log_transform=False\n",
    ")\n",
    "\n",
    "# LightGBMの学習する際のパラメーター\n",
    "params = {\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"sub_feature\": 0.7,\n",
    "    \"num_leaves\": 60,\n",
    "    \"min_data\": 1,\n",
    "    \"min_hessian\": 1,\n",
    "    \"verbose_eval\": -1,\n",
    "}\n",
    "\n",
    "# 訪問者数に対数をとった場合のデータセットを学習に使う特徴量と目的変数をLightGBM用のDatasetに格納する\n",
    "lgb_train_log = lgb.Dataset(train_log[predictors_log], target_log)\n",
    "# LightGBMを学習する\n",
    "gbm_log = lgb.train(params, lgb_train_log, 1000)\n",
    "# LightGBMのモデルを使って、テスト用の特徴量から訪問者数を予測\n",
    "pred_log = gbm_log.predict(test_log[predictors_log])\n",
    "\n",
    "# 訪問者数のデータセットを学習に使う特徴量と目的変数をLightGBM用のDatasetに格納する\n",
    "lgb_train = lgb.Dataset(train[predictors], target)\n",
    "# LightGBMを学習する\n",
    "gbm = lgb.train(params, lgb_train, 1000)\n",
    "# LightGBMのモデルを使って、テスト用の特徴量から訪問者数を予測\n",
    "pred = gbm.predict(test[predictors])\n",
    "\n",
    "# 教師データである訪問者数に対数をとった場合のデータセットを使って学習したモデルの訪問者数の予測精度を測るためにMean Absolute Errorを求める\n",
    "mae_log = f\"{mean_absolute_error(test['visitors'].values,np.expm1(pred_log)):.3f}\"\n",
    "# 訪問者数のデータセットを使って学習したモデルの訪問者数の予測精度を測るためにMean Absolute Errorを求める\n",
    "mae = f\"{mean_absolute_error(test['visitors'].values,pred):.3f}\"\n",
    "\n",
    "print(pd.DataFrame([[mae_log, mae]], columns=[\"モデル1\", \"モデル2\"], index=[\"mae\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321f9357",
   "metadata": {},
   "source": [
    "### 2-4 平均絶対パーセント誤差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cae4559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# 教師データである訪問者数に対数をとった場合のデータセットを使って学習したモデルで平均絶対パーセント誤差を算出する\n",
    "mape_log = mean_absolute_percentage_error(test[\"visitors\"].values, np.expm1(pred_log))\n",
    "# 訪問者数のデータセットを使って学習したモデルで平均絶対パーセント誤差を算出する\n",
    "mape = mean_absolute_percentage_error(test[\"visitors\"].values, pred)\n",
    "\n",
    "print(pd.DataFrame([[f\"{mape_log:.3f}\",f\"{mape:.3f}\"]], columns=[\"モデル1\", \"モデル2\"], index=[\"mae\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4753576c",
   "metadata": {},
   "source": [
    "### 2-5 二乗平均平方誤差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5350259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 教師データである訪問者数に対数をとった場合のデータセットを使って学習したモデルで二乗平均平方誤差を算出する\n",
    "rmse_log = mean_squared_error(test[\"visitors\"].values, np.expm1(pred_log), squared=False)\n",
    "# 訪問者数のデータセットを使って学習したモデルで二乗平均平方誤差を算出する\n",
    "rmse = mean_squared_error(test[\"visitors\"].values,pred, squared=False)\n",
    "\n",
    "print(pd.DataFrame([[f\"{rmse_log:.3f}\", f\"{rmse:.3f}\"]], columns=[\"モデル1\", \"モデル2\"], index=[\"mae\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4635e29",
   "metadata": {},
   "source": [
    "### 2-6 対数平均二乗誤差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb3d6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "# 教師データである訪問者数に対数をとった場合のデータセットを使って学習したモデルで対数平均二乗誤差を算出する\n",
    "# mean_squared_error(test_log['visitors'].values, pred_log, squared=False)でも同じ値になる\n",
    "rmsle_log = mean_squared_log_error(test[\"visitors\"].values, np.expm1(pred_log), squared=False)\n",
    "# 訪問者数のデータセットを使って学習したモデルで対数平均二乗誤差を算出する\n",
    "rmsle = mean_squared_log_error(test[\"visitors\"].values, pred, squared=False)\n",
    "\n",
    "print(pd.DataFrame([[f\"{rmsle_log:.3f}\", f\"{rmsle:.3f}\"]], columns=[\"モデル1\", \"モデル2\"], index=[\"mae\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010f2688",
   "metadata": {},
   "source": [
    "### 2-7-2 モデルの解釈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030ebaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト用データの実際の合計訪問数と訪問者数に対数をとった場合のデータセットで学習したモデルが予測した合計訪問数を表示\n",
    "print(test[\"visitors\"].sum(), np.expm1(pred_log).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ca443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト用データの実際の合計訪問数と訪問者数のデータセットを使って学習したモデルが予測した合計訪問数を表示\n",
    "print(test[\"visitors\"].sum(), pred.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821ae72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訪問日からウィークナンバー（週番号）を取得\n",
    "weeks = [datetime.strptime(eval_day, '%Y-%m-%d').isocalendar().week for eval_day in test[\"visit_date\"]]\n",
    "# ウィークナンバー（週番号）をカラムに追加する\n",
    "test[\"weeks\"] = weeks\n",
    "# 訪問者数に対数をとった場合のデータセットで学習したモデルが予測した値をカラムに追加する\n",
    "test[\"pred_log\"] = np.expm1(pred_log)\n",
    "# 訪問者数に訪問者数のデータセットを使って学習したモデルが予測した値をカラムに追加する\n",
    "test[\"pred\"] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b1b7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 週ごとの実際の合計訪問人数と訪問者数に対数をとった場合のデータセットで学習したモデルが予測した合計訪問数を集計\n",
    "weekly_sum_log = test.groupby(\"weeks\")[[\"visitors\",\"pred_log\"]].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19c7a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの予測した合計訪問数の方が実際の合計訪問者数より多い場合には実際の合計訪問者数をtrue_visitorsに格納し、そうでない場合はモデルが予測した合計訪問数をtrue_visitorsに格納\n",
    "weekly_sum_log[\"true_visitors\"] = np.where(weekly_sum_log['pred_log'] > weekly_sum_log['visitors'], weekly_sum_log['visitors'].astype(int), weekly_sum_log['pred_log'].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffcb00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 週ごとの利益を計算\n",
    "weekly_sum_log[\"weekly_profit\"] = 5000 * weekly_sum_log[\"true_visitors\"]  - (1500 * 3) * 11 * 7 - 2000 * weekly_sum_log[\"pred_log\"] - 250000 / 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf1fe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 週ごとのレポートを表示\n",
    "weekly_sum_log[['weeks', 'true_visitors',  'pred_log', 'weekly_profit']].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca28349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 週ごとの実際の合計訪問人数と訪問者数のデータセットを使って学習したモデルが予測した合計訪問数を集計\n",
    "weekly_sum = test.groupby(\"weeks\")[[\"visitors\", \"pred\"]].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2000151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの予測した合計訪問数の方が実際の合計訪問者数より多い場合には実際の合計訪問者数をtrue_visitorsに格納し、そうでない場合はモデルが予測した合計訪問数をtrue_visitorsに格納\n",
    "weekly_sum[\"true_visitors\"] = np.where(weekly_sum['pred'] > weekly_sum['visitors'], weekly_sum['visitors'].astype(int), weekly_sum['pred'].astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf133df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 週ごとの利益を計算\n",
    "weekly_sum[\"weekly_profit\"] = 5000 * weekly_sum[\"true_visitors\"]  - (1500 * 3) * 11 * 7  - 2000 *  weekly_sum[\"pred\"]  - 250000/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d620fd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 週ごとのレポートを表示\n",
    "weekly_sum[['weeks', 'true_visitors',  'pred', 'weekly_profit']].round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc7a0a7",
   "metadata": {},
   "source": [
    "### 2-8-1 平均二乗誤差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e675ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 教師データである訪問者数に対数をとった場合のデータセットを使って学習したモデルで平均二乗誤差を算出する\n",
    "mse_log = mean_squared_error(test[\"visitors\"].values, np.expm1(pred_log))\n",
    "# 訪問者数のデータセットを使って学習したモデルで平均二乗誤差を算出する\n",
    "mse = mean_squared_error(test[\"visitors\"].values, pred)\n",
    "\n",
    "print(pd.DataFrame([[f\"{mse_log:.3f}\", f\"{mse:.3f}\"]], columns=[\"モデル1\", \"モデル2\"], index=[\"mse\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817c1b55",
   "metadata": {},
   "source": [
    "### 2-8-2 平均ポアソン逸脱度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be883a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_poisson_deviance\n",
    "\n",
    "# 教師データである訪問者数に対数をとった場合のデータセットを使って学習したモデルで平均ポアソン逸脱度を算出する\n",
    "mpd_log = mean_poisson_deviance(test[\"visitors\"].values, np.expm1(pred_log))\n",
    "# 訪問者数のデータセットを使って学習したモデルで平均ポアソン逸脱度を算出する\n",
    "mpd = mean_poisson_deviance(test[\"visitors\"].values, pred)\n",
    "\n",
    "print(pd.DataFrame([[f\"{mpd_log:.3f}\", f\"{mpd:.3f}\"]], columns=[\"モデル1\", \"モデル2\"], index=[\"poisson\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b602ec06",
   "metadata": {},
   "source": [
    "### 2-8-3 平均ガンマ逸脱度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305e12cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_gamma_deviance\n",
    "\n",
    "# 教師データである訪問者数に対数をとった場合のデータセットを使って学習したモデルで平均ガンマ逸脱度を算出する\n",
    "mgd_log = mean_gamma_deviance(test[\"visitors\"].values, np.expm1(pred_log))\n",
    "# 訪問者数のデータセットを使って学習したモデルで平均ガンマ逸脱度を算出する\n",
    "mgd = mean_gamma_deviance(test[\"visitors\"].values ,pred)\n",
    "\n",
    "print(pd.DataFrame([[f\"{mgd_log:.3f}\", f\"{mgd:.3f}\"]], columns=[\"モデル1\", \"モデル2\"], index=[\"gamma\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7900dd62",
   "metadata": {},
   "source": [
    "### 2-8-5 平均Tweedie逸脱度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a104b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_tweedie_deviance\n",
    "\n",
    "# 教師データである訪問者数に対数をとった場合のデータセットを使って学習したモデルで平均Tweedie逸脱度を算出する\n",
    "mtd_log = mean_tweedie_deviance(test[\"visitors\"].values,np.expm1(pred_log))\n",
    "# 訪問者数のデータセットを使って学習したモデルで平均Tweedie逸脱度を算出する\n",
    "mtd = mean_tweedie_deviance(test[\"visitors\"].values,pred)\n",
    "\n",
    "print(pd.DataFrame([[f\"{mtd_log:.3f}\", f\"{mtd:.3f}\"]], columns=[\"モデル1\", \"モデル2\"], index=[\"tweedie\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da318f67",
   "metadata": {},
   "source": [
    "### 2-8-6 決定係数$R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8a6ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 教師データである訪問者数に対数をとった場合のデータセットを使って学習したモデルで決定係数を算出する\n",
    "r2s_log = r2_score(test[\"visitors\"].values, np.expm1(pred_log))\n",
    "# 訪問者数のデータセットを使って学習したモデルで決定係数を算出する\n",
    "r2s = r2_score(test[\"visitors\"].values, pred)\n",
    "\n",
    "print(pd.DataFrame([[f\"{r2s_log:.3f}\", f\"{r2s:.3f}\"]], columns=[\"モデル1\", \"モデル2\"], index=[\"R2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12355d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.5",
   "language": "python",
   "name": "3.10.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
